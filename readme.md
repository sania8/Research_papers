Papers are : 
1. Computational models of category-selective brain regions enable high-throughput tests of selectivity
   N. Apurva Ratan Murty, Pouya Bashivan, Alex Abate, James J. DiCarlo & Nancy Kanwisher 
2. SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models
   Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, Animesh Garg
The 1. Paper talked about studying of activation of different brain regions ie, (Fusiform Face Area(FFA) ,parahippocampal place area(PPA) , Extratriate Body Area(EBA) ) by looking at stimuli (images , face , body , area etc) . The paper also tells about Category selectivity which is to what degree the different regions of brain responds to the parts(features) of stimuli for the use of GAN was introduced in the paper.
The 2. paper talks about video prediction b taking in videos extrating frames and to see how different objects are interating with one another and how are they changing their position with time . The model used works on the object-centric model technique . The learning is sequence-by-sequence learning.ğŸ“šğŸ§  Research Papers Overview ğŸ¬ğŸ”

Welcome to the Research Papers Overview! Dive into the fascinating world of neuroscience and visual dynamics with these groundbreaking studies:

1ï¸âƒ£ **Computational models of category-selective brain regions enable high-throughput tests of selectivity**
   
   ğŸ“ Authors: N. Apurva Ratan Murty, Pouya Bashivan, Alex Abate, James J. DiCarlo & Nancy Kanwisher
   
   ğŸ§  This paper delves into the activation patterns of different brain regions: Fusiform Face Area (FFA), Parahippocampal Place Area (PPA), and Extrastriate Body Area (EBA). It explores how these regions respond to stimuli such as images, faces, and bodies, uncovering category selectivity. Introduction of Generative Adversarial Networks (GANs) enriches the understanding of neural selectivity.

2ï¸âƒ£ **SlotFormer: Unsupervised Visual Dynamics Simulation with Object-Centric Models**

   ğŸ“ Authors: Ziyi Wu, Nikita Dvornik, Klaus Greff, Thomas Kipf, Animesh Garg
   
   ğŸ¥ This paper ventures into video prediction by extracting frames and analyzing object interactions over time. Leveraging object-centric models, it investigates how different objects interact and change positions. The model's approach involves sequence-by-sequence learning for comprehensive understanding of visual dynamics.


ğŸŒŸ Immerse yourself in the frontier of scientific exploration with these captivating papers! For any inquiries or discussions, feel free to reach out. Happy exploring! ğŸ§ ğŸ¬
